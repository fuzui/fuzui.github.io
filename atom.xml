<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>扶醉</title>
  
  <subtitle>fuzui.net</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-04-03T12:12:05.065Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>王泽</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>HIVE的搭建配置及关联MySQL</title>
    <link href="http://yoursite.com/2019/04/03/hive/"/>
    <id>http://yoursite.com/2019/04/03/hive/</id>
    <published>2019-04-03T07:37:58.000Z</published>
    <updated>2019-04-03T12:12:05.065Z</updated>
    
    <content type="html"><![CDATA[<p><strong>概念：</strong></p><blockquote><p>Hive是由Facebook实现并开源。是基于Hadoop的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供HQL（Hive SQL）查询功能。其底层数据时存储在HDFS上。Hive的本质是将SQL语句转换为MapReduce任务运行，使部署需MapReduce的用户很方便地利用HQL处理和计算HDFS上的结构化数据，使用于离线的批量数据计算。</p></blockquote><a id="more"></a><h4 id="一、下载"><a href="#一、下载" class="headerlink" title="一、下载"></a>一、下载</h4><p><strong>前提：</strong> 配置好hadoop分布式环境，我在上一篇博文写到<a href="https://fuzui.net/2019/03/27/hadoop-fully-distributed/" target="_blank" rel="noopener">Hadoop从零开始搭建完全分布式</a>。</p><p>官网下载hive，这里我用hive-1.2.2版本：官网下载地址：<a href="http://mirrors.shu.edu.cn/apache/hive/hive-1.2.2/" target="_blank" rel="noopener">http://mirrors.shu.edu.cn/apache/hive/hive-1.2.2/</a></p><p>我这里选择下载到本地然后通过xftp上传到虚拟机上。<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403160608.png" alt></p><p>解压：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf apache-hive-1.2.2-bin.tar.gz</span><br></pre></td></tr></table></figure></p><p>重命名<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv apache-hive-1.2.2-bin hive-1.2.2</span><br></pre></td></tr></table></figure></p><h4 id="二、配置"><a href="#二、配置" class="headerlink" title="二、配置"></a>二、配置</h4><p>（1）配置环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure></p><p>将以下添加在末尾<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_HOME=/software/hive-1.2.2</span><br><span class="line">PAHT=$PATH:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure></p><p>刷新<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>查看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403162230.png" alt><br>（2）配置文件<br>修改software/hive-1.2.2/conf/hive-env.sh.template为hive-env.sh。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /software/hive-1.2.2/conf/</span><br><span class="line">cp hive-env.sh.template hive-env.sh</span><br></pre></td></tr></table></figure></p><ul><li>配置HADOOP_HOME=/Hadoop所在路径</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/software/hadoop2.7.2</span><br></pre></td></tr></table></figure><ul><li>配置HIVE_CONF_DIR=/Hive中conf文件夹路径<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export HIVE_CONF_DIR=/software/hive-1.2.2/conf</span><br></pre></td></tr></table></figure></li></ul><h4 id="三、启动"><a href="#三、启动" class="headerlink" title="三、启动"></a>三、启动</h4><p>（1）启动HDFS<br>在hadoop01机上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure></p><p>（2）启动YARN<br>在hadoop02机上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></p><p>通过jps检测启动情况<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403163744.png" alt><br>（3）在HDFS上创建/tmp和/user/hive/warehouse<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /tmp</span><br><span class="line">hadoop fs -mkdir -p /user/hive/warehouse</span><br></pre></td></tr></table></figure></p><p>（4）修改文件夹权限，同组可写<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -chmod 775 /tmp</span><br><span class="line">hadoop fs -chmod 775 /user/hive/warehouse</span><br></pre></td></tr></table></figure></p><p>（5）启动Hive<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403164248.png" alt></p><h4 id="四、hive基本操作"><a href="#四、hive基本操作" class="headerlink" title="四、hive基本操作"></a>四、hive基本操作</h4><p>1.基本操作(语法类似于MySQL)<br>2.显示所有数据库：show databases;<br>3.使用数据库(默认数据库default):use 数据库名;<br>4.显示使用数据库下所有表:show tables;<br>5.创建表:create table 表名(字段1 类型,字段2 类型…)<br>6.插入数据(map reduce):insert into 表名 (字段1,字段2…) values (数据1,数据2…)<br>7.查询数据:select 字段 from 表名;<br>8.删除表:drop table 表名;<br>9.退出:exit</p><h4 id="五、安装mysql"><a href="#五、安装mysql" class="headerlink" title="五、安装mysql"></a>五、安装mysql</h4><h5 id="1-卸载Mariadb"><a href="#1-卸载Mariadb" class="headerlink" title="1. 卸载Mariadb"></a>1. 卸载Mariadb</h5><p>CentOS7自带的是 Mariadb<br>（1）查找<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -qa|grep mariadb</span><br></pre></td></tr></table></figure></p><p>（2）删除<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rpm -e --nodeps 上面查出来的文件名</span><br></pre></td></tr></table></figure></p><p>（3）删除配置文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm /etc/my.cnf</span><br></pre></td></tr></table></figure></p><h5 id="2-下载mysql-8-0"><a href="#2-下载mysql-8-0" class="headerlink" title="2.下载mysql 8.0"></a>2.下载mysql 8.0</h5><p>这里我通过rpm安装<br>官网下载：<a href="https://dev.mysql.com/downloads/file/?id=484537" target="_blank" rel="noopener">mysql8.0.15</a><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403165951.png" alt><br>（1）解压<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -xvf mysql-8.0.15-1.el7.x86_64.rpm-bundle.tar</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403170217.png" alt><br>（2）安装<br>解决一些依赖<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum -y install numactl    </span><br><span class="line">yum -y install libaio.so.1 libgcc_s.so.1 libstdc++.so.6</span><br><span class="line">yum update libstdc++-4.4.7-4.el6.x86_64</span><br><span class="line">yum search libaio</span><br><span class="line">yum install libaio</span><br><span class="line">yum install net-tools</span><br><span class="line">yum install openssl-devel</span><br></pre></td></tr></table></figure></p><p>按次序安装<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">rpm -ivh MySQL-client-5.6.43-1.el7.x86_64.rpmrpm -ivh mysql-community-common-8.0.15-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-libs-8.0.15-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-client-8.0.15-1.el7.x86_64.rpm</span><br><span class="line">rpm -ivh mysql-community-server-8.0.15-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure></p><p>（3）初始化<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqld --initialize --user=mysql --basedir=/usr --datadir=/var/lib/mysql</span><br></pre></td></tr></table></figure></p><p>（4）启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mysqld</span><br></pre></td></tr></table></figure></p><p>（5）修改密码</p><ul><li>编辑配置文件<br>vim /etc/my.cnf<br>在[mysqld]下添加skip-grant-tables<br>保存退出</li><li>重启mysql服务<br>systemctl restart mysqld</li><li>通过mysql -uroot -p<br>登录，密码直接回车即可</li><li>选择mysql数据库<br>use mysql;</li><li>将默认密码清空<br>update user set authentication_string=’’ where user=’root’;<br>exit命令退出</li><li>删除 /etc/my.cnf 文件刚刚添加的 skip-grant-tables<br>vim /etc/my.cnf<br>选中skip-grant-tables所在行按两下d键即可删除<br>保存退出</li><li>重启mysql服务<br>systemctl restart mysqld</li><li>再次登录<br>mysql -uroot -p<br>登录，密码直接回车即可</li><li>设置密码（我这里将密码设为root）<br>选择mysql数据库<br>use mysql;<br>ALTER user ‘root‘@’localhost’ IDENTIFIED BY ‘root’;</li><li>设置远程访问<br>update user set host=’%’ where user=’root’;</li><li>重启<br>exit退出<br>重启服务systemctl restart mysqld<br>重新通过mysql -uroot -proot登录</li><li>远程连接<br>我通过navicat远程连接，<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403182935.png" alt></li><li>设置开机启动<br>systemctl enable mysqld</li></ul><p>至此，mysql安装完成。</p><h4 id="六、hive关联mysql"><a href="#六、hive关联mysql" class="headerlink" title="六、hive关联mysql"></a>六、hive关联mysql</h4><h5 id="1-下载驱动jar"><a href="#1-下载驱动jar" class="headerlink" title="1.下载驱动jar"></a>1.下载驱动jar</h5><p>我安装的是mysql8.0.15版本，我找对应版本的jar<br>平时个人比较喜欢到mvnrepository去找jar，附上地址：<a href="https://mvnrepository.com/artifact/mysql/mysql-connector-java/8.0.15" target="_blank" rel="noopener">https://mvnrepository.com/artifact/mysql/mysql-connector-java/8.0.15</a></p><p>将下载好的jar放到hadoop01虚拟机中hive安装目录的lib文件夹下<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403183816.png" alt></p><h5 id="2-配置hive-site-xml"><a href="#2-配置hive-site-xml" class="headerlink" title="2.配置hive-site.xml"></a>2.配置hive-site.xml</h5><p>创建hive-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /software/hive-1.2.2/conf</span><br><span class="line">vim hive-site.xml</span><br></pre></td></tr></table></figure></p><p>将以下添加进去（灵活应变）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;jdbc:mysql://192.168.17.134:3306/myhive?createDatabaseIfNotExist=true&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;com.mysql.cj.jdbc.Driver&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;root&lt;/value&gt;</span><br><span class="line">        &lt;/property&gt;</span><br><span class="line">        &lt;property&gt;</span><br><span class="line">                &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;root&lt;/value&gt;</span><br><span class="line"> &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure></p><h5 id="3-重启整个集群"><a href="#3-重启整个集群" class="headerlink" title="3.重启整个集群"></a>3.重启整个集群</h5><p>（1）在Hadoop02上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-yarn.sh</span><br></pre></td></tr></table></figure></p><p>（2）在Hadoop01上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">stop-dfs.sh</span><br></pre></td></tr></table></figure></p><p>（3）在Hadoop01上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure></p><p>（4）在Hadoop02上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></p><p>（5）在Hadoop01上重启mysql<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart mysqld</span><br></pre></td></tr></table></figure></p><h5 id="4-启动"><a href="#4-启动" class="headerlink" title="4.启动"></a>4.启动</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403190805.png" alt><br>启动完成后用navicat查看发现已经自动创建了myhive数据库。<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403190031.png" alt><br>也可以通过命令行查看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -proot</span><br><span class="line">show databases;</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403190923.png" alt></p><h5 id="5-其他配置（看需求）"><a href="#5-其他配置（看需求）" class="headerlink" title="5.其他配置（看需求）"></a>5.其他配置（看需求）</h5><p>hive-site.xml中<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#数据库存放位置</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; </span><br><span class="line">&lt;value&gt;/user/hive/warehouse&lt;/value&gt;</span><br><span class="line">&lt;description&gt;location of default database for the warehouse&lt;/description&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">#查询时显示字段名称和数据库名</span><br><span class="line">&lt;property&gt; </span><br><span class="line">&lt;name&gt;hive.cli.print.header&lt;/name&gt;</span><br><span class="line">&lt;value&gt;true&lt;/value&gt; </span><br><span class="line">&lt;/property&gt; </span><br><span class="line">&lt;property&gt; </span><br><span class="line">&lt;name&gt;hive.cli.print.current.db&lt;/name&gt;</span><br><span class="line"> &lt;value&gt;true&lt;/value&gt; </span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><h4 id="七、测试"><a href="#七、测试" class="headerlink" title="七、测试"></a>七、测试</h4><p>（1）进入数据库<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">create database fuzui;</span><br><span class="line">use fuzui;</span><br></pre></td></tr></table></figure></p><p>（2）创建表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create table student(</span><br><span class="line">    id int, </span><br><span class="line">    name string, </span><br><span class="line">    age int, </span><br><span class="line">    sex string)</span><br><span class="line">row format delimited fields terminated by &apos;,&apos;;</span><br></pre></td></tr></table></figure><p>在mysql中会看到创建这个表的字段信息<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403200116.png" alt><br>（3）退出hive<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exit</span><br></pre></td></tr></table></figure></p><p>（4）创建本地文件上传到HDFS</p><p><1>我直接用的root用户，所以我在root目录下创建<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /root</span><br><span class="line">vim fz.txt</span><br></pre></td></tr></table></figure></1></p><p>添加如下内容<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">201501,wangze,22,man</span><br><span class="line">201502,wangchen,20,man</span><br><span class="line">201503,liyu,20,woman</span><br><span class="line">201504,zhangna,21,woman</span><br><span class="line">201505,songxin,19,woman</span><br><span class="line">201506,changyi,18,man</span><br><span class="line">201507,liuni,20,woman</span><br><span class="line">201508,zhaoming,22,man</span><br></pre></td></tr></table></figure></p><p>保存退出</p><p><2>上传hdfs</2></p><ul><li>创建文件夹<br><code>hadoop fs -mkdir /myhive</code></li><li>上传<br><code>hadoop fs -put /root/fz.txt /myhive</code></li><li>查看<br><code>hadoop fs -cat /myhive/fz.txt</code><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403193537.png" alt><br>（5）进入hive<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hive</span><br></pre></td></tr></table></figure></li></ul><p>（6）导入hive表</p><ul><li>进入数据库<br>  <code>use fuzui</code></li><li><p>导入<br><code>load data inpath &#39;/myhive/fz.txt&#39; into table student;</code><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403194307.png" alt></p></li><li><p>查看数据<br><code>select * from student;</code><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403194417.png" alt></p></li><li><p>稍微复杂点的查询<br>查询最小的女生多少岁<br><code>select min(age) from student where sex = &#39;woman&#39;;</code><br>这时，就开始一系列运行了，速度会慢。</p></li></ul><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190403195629.png" alt></p><p><strong><em>==至此，HIVE搭建成功！==</em></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;概念：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Hive是由Facebook实现并开源。是基于Hadoop的一个数据仓库工具，可以将结构化的数据映射为一张数据库表，并提供HQL（Hive SQL）查询功能。其底层数据时存储在HDFS上。Hive的本质是将SQL语句转换为MapReduce任务运行，使部署需MapReduce的用户很方便地利用HQL处理和计算HDFS上的结构化数据，使用于离线的批量数据计算。&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
      <category term="hive" scheme="http://yoursite.com/tags/hive/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop从零开始搭建完全分布式</title>
    <link href="http://yoursite.com/2019/03/27/hadoop-fully-distributed/"/>
    <id>http://yoursite.com/2019/03/27/hadoop-fully-distributed/</id>
    <published>2019-03-27T15:34:48.000Z</published>
    <updated>2019-04-03T04:28:21.978Z</updated>
    
    <content type="html"><![CDATA[<p><strong>简介：</strong></p><blockquote><p>由三个或以上实体机或虚拟机组成的集群。</p></blockquote><p><strong>准备：</strong></p><blockquote><p>1.hadoop2.7.2版本<br>2.jdk8版本<br>3.vmware</p></blockquote><a id="more"></a><h4 id="一、创建虚拟机及相关配置"><a href="#一、创建虚拟机及相关配置" class="headerlink" title="一、创建虚拟机及相关配置"></a>一、创建虚拟机及相关配置</h4><h5 id="1-创建虚拟机"><a href="#1-创建虚拟机" class="headerlink" title="1.创建虚拟机"></a>1.创建虚拟机</h5><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/1553754905885.png" alt><br>一路下一步，选择已有centos7镜像<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328143641.png" alt><br>这里我取名为hadoop01<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328143753.png" alt><br>选择NAT网络模式<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328143852.png" alt><br>设置相关硬件<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328144135.png" alt><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328144100.png" alt><br>然后等待创建（中间空的步骤均使用默认）<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328144756.png" alt><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328145249.png" alt><br>开始安装：<br>设置root密码和创建一个用户<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328145401.png" alt><br>等待安装完成</p><h5 id="2-查看ip并修改主机名以及配置映射"><a href="#2-查看ip并修改主机名以及配置映射" class="headerlink" title="2.查看ip并修改主机名以及配置映射"></a>2.查看ip并修改主机名以及配置映射</h5><p>（1）查看并修改ip<br>我将这一台的ip设为192.168.17.134<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd /etc/sysconfig/network-scripts/</span><br><span class="line">vim vi ifcfg-ens33</span><br><span class="line">#这个配置每个人都可能不一样，进去修改</span><br></pre></td></tr></table></figure></p><p>将原来的完全替换（灵活修改name和device）<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">TYPE=Ethernet</span><br><span class="line">BOOTPROTO=static</span><br><span class="line">NAME=ens33</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=192.168.17.134</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=192.168.17.2</span><br><span class="line">DNS1=8.8.8.8</span><br></pre></td></tr></table></figure></p><p>重启reboot<br>ping <a href="http://www.baidu.com查看网络是否通" target="_blank" rel="noopener">www.baidu.com查看网络是否通</a></p><p>永久关闭防火墙：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br></pre></td></tr></table></figure><p>这里我使用的secureCRT连接我的虚拟机。<br>（2）修改主机名<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hostname</span><br><span class="line">修改为hadoop01</span><br></pre></td></tr></table></figure></p><p>（3）配置ip映射<br>预计后面两台虚拟机的ip分别是192.168.17.135和192.168.17.136<br>有以下关系</p><table><thead><tr><th>主机</th><th>ip</th></tr></thead><tbody><tr><td>hadoop01</td><td>192.168.17.134</td></tr><tr><td>hadoop02</td><td>192.168.17.135</td></tr><tr><td>hadoop03</td><td>192.168.17.134</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/hosts</span><br><span class="line">#</span><br><span class="line">127.0.0.1   localhost</span><br><span class="line">192.168.17.134   hadoop01</span><br><span class="line">192.168.17.135   hadoop02</span><br><span class="line">192.168.17.136   hadoop03</span><br></pre></td></tr></table></figure><p>重启reboot</p><h5 id="3-上传hadoop和jdk并配置环境变量"><a href="#3-上传hadoop和jdk并配置环境变量" class="headerlink" title="3.上传hadoop和jdk并配置环境变量"></a>3.上传hadoop和jdk并配置环境变量</h5><p>（1）安装ftp</p><p>安装ftp<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install vsftpd lftp ftp</span><br></pre></td></tr></table></figure></p><p>（2）上传<br>这里我使用的是xftp6工具<br>上传相关包<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328150814.png" alt><br>然后创建相关目录并解压<br>我在根目录下创建software<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /software</span><br></pre></td></tr></table></figure></p><p>将hadoop和jdk解压并重命名放在其下。（解压移动重命名基础过程省略）</p><p>（3）配置环境变量<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br></pre></td></tr></table></figure></p><p>在后面添加<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/software/jdk1.8</span><br><span class="line">export HADOOP_HOME=/software/hadoop2.7.2</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure></p><p>刷新生效<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure></p><p>检测<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo $PATH</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328162516.png" alt></p><h5 id="3-修改hadoop配置文件"><a href="#3-修改hadoop配置文件" class="headerlink" title="3.修改hadoop配置文件"></a>3.修改hadoop配置文件</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /software/hadoop2.7.2/etc/hadoop/</span><br></pre></td></tr></table></figure><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328162713.png" alt></p><p>vi修改，以下xml文件修改在configuration标签内<br>1.core-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hdfs://hadoop01:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/software/hadoop2.7.2/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>2.hadoop-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/software/jdk1.8</span><br></pre></td></tr></table></figure></p><p>3.hdfs-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;3&lt;/balue&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop03:50090&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>4.slavs</p><p><font color="red">配置datanode节点的ip，每个占一行，不能出现多余的空格和换行行</font><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">192.168.17.134</span><br><span class="line">192.168.17.135</span><br><span class="line">192.168.17.136</span><br></pre></td></tr></table></figure></p><p>5.yarn-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/software/jdk1.8</span><br></pre></td></tr></table></figure></p><p>6.yarn-site.xml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop02&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>7.mapre-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export $JAVA_HOME=/software/jdk1.8</span><br></pre></td></tr></table></figure></p><p>8.mapred-site.xml<br>将mapred-site.xml.template重命名<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>至此，一台配置完成，紧接着克隆出两台一模一样的</p><h4 id="二、克隆并配置"><a href="#二、克隆并配置" class="headerlink" title="二、克隆并配置"></a>二、克隆并配置</h4><h5 id="1-克隆"><a href="#1-克隆" class="headerlink" title="1.克隆"></a>1.克隆</h5><p>首先关机刚刚虚拟机<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328163857.png" alt><br>下一步，创建完整克隆<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328163944.png" alt><br>更名为hadoop02。<br>以此方法克隆出hadoop03。</p><h5 id="2-修改配置"><a href="#2-修改配置" class="headerlink" title="2.修改配置"></a>2.修改配置</h5><p>（1）分别修改主机名和ip<br>hadoop02    192.168.17.135<br>hadoop03    192.168.17.136<br>（2）重启reboot</p><h5 id="3-创建免密登录"><a href="#3-创建免密登录" class="headerlink" title="3.创建免密登录"></a>3.创建免密登录</h5><p>三台机器都执行ssh-keygen -t rsa,一路回车<br>cd ~/.ssh   查看</p><p>再分别执行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id hadoop01</span><br><span class="line">ssh-copy-id hadoop02</span><br><span class="line">ssh-copy-id hadoop03</span><br></pre></td></tr></table></figure></p><p>检测<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ssh hadoop02</span><br><span class="line">ssh hadoop03</span><br></pre></td></tr></table></figure></p><h4 id="二、启动集群"><a href="#二、启动集群" class="headerlink" title="二、启动集群"></a>二、启动集群</h4><h5 id="1-启动"><a href="#1-启动" class="headerlink" title="1.启动"></a>1.启动</h5><p>（1）格式化namenode<br>在hadoop01上<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure></p><p>（2）启动NameNode和DataNode(在hadoop01上)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure></p><p>（3）启动ResourceManager和NodeMananger(在hadoop02上)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure></p><h5 id="2-检测"><a href="#2-检测" class="headerlink" title="2.检测"></a>2.检测</h5><p>（1）jps检测<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328182607.png" alt></p><p>（2）登录web 192.168.17.134:50070<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328182651.png" alt></p><h4 id="三、测试"><a href="#三、测试" class="headerlink" title="三、测试"></a>三、测试</h4><h5 id="1-创建并上传hdfs测试文本"><a href="#1-创建并上传hdfs测试文本" class="headerlink" title="1.创建并上传hdfs测试文本"></a>1.创建并上传hdfs测试文本</h5><p>（1）本地通过vi创建了一个wz.txt，并编辑文本<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328183139.png" alt><br>（2）上传到hdfs上<br>创建输入文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /data/input</span><br></pre></td></tr></table></figure></p><p>将wz.txt上传<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put /root/wz.txt /data/input</span><br></pre></td></tr></table></figure></p><p>查看<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /data/input/wz.txt</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328183609.png" alt></p><h5 id="2-执行官网测试wordcount"><a href="#2-执行官网测试wordcount" class="headerlink" title="2.执行官网测试wordcount"></a>2.执行官网测试wordcount</h5><p><font color="red">输出文件夹事先不能有！</font><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar /software/hadoop2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /data/input /data/output</span><br></pre></td></tr></table></figure></p><p>中间部分过程<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184038.png" alt><br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184127.png" alt><br>执行完成<br>查看输出文件夹<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /data/output/</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184236.png" alt><br>其中part-r-00000便是输出结果<br>查看：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /data/output/part-r-00000</span><br></pre></td></tr></table></figure></p><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184355.png" alt></p><p>也可以通过192.168.17.134:50070查看<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184619.png" alt><br>点进data——output<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184722.png" alt><br>点击part-r-00000<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184751.png" alt></p><p>下载这块，如果想点击下载，需要在你本机上配置ip映射（或者点击下载后吧url上的hadoop02换成192.168.17.135也是可以的=-=）<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328184940.png" alt></p><p>win10上ip映射文件位置<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20190328185235.png" alt></p><p><br><br><br></p><p><strong><em>==至此，完全分布式搭建成功！==</em></strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;简介：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;由三个或以上实体机或虚拟机组成的集群。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;准备：&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1.hadoop2.7.2版本&lt;br&gt;2.jdk8版本&lt;br&gt;3.vmware&lt;/p&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop搭建伪分布式</title>
    <link href="http://yoursite.com/2019/03/25/Hadoop-pseudo-distributed/"/>
    <id>http://yoursite.com/2019/03/25/Hadoop-pseudo-distributed/</id>
    <published>2019-03-25T11:35:18.000Z</published>
    <updated>2019-03-26T09:08:46.153Z</updated>
    
    <content type="html"><![CDATA[<h3 id="概念"><a href="#概念" class="headerlink" title="==概念=="></a>==概念==</h3><blockquote><p>海量、高增长、多样化的信息数据<br>有三大发行版本</p><blockquote><p>Apache、CDH、HDP</p></blockquote></blockquote><a id="more"></a><h4 id="一、优势"><a href="#一、优势" class="headerlink" title="一、优势"></a>一、优势</h4><p><strong>1、高可靠性：</strong><br>Hadoop假设计算元素和存储会出现故障，因为它维护多个工作数据副本，在出现故障时可以对失败节点重新分布处理。<br><strong>2.高扩展性：</strong><br>在集群间分配任务数据，可方便扩展数以千计的节点。<br><strong>3.高效性：</strong><br>在MapReduce的思想下，Hadoop是并行工作的，以加快任务处理速度。<br><strong>4.高容错性：</strong><br>自动保存多份副本数据，并且能够自动将失败的任务重新分配。</p><h4 id="二、组成"><a href="#二、组成" class="headerlink" title="二、组成"></a>二、组成</h4><ul><li>Hadoop HDFS：一个高可靠、高吞吐的分布式文件系统。</li><li>Hadoop MapReduce：一个分布式的离线并行计算框架。</li><li>Hadoop YARN：一个资源调度平台，负责为运算程序提供服务器运算资源，相当于一个分布式的操作系统，而MaoReduce等运算程序则相当于运算于操作系统之上的应用程序。</li><li>ResourceManager：一个中心服务，用来调度、启动每一个Job所属的ApplicationMaster。</li><li>NodeManager：是每台机器框架的代理，是执行应用程序的容器，监控应用程序的资源使用情况，并向调度器汇报。</li><li><p>Hadoop Common：Hadoop体系最底层的一个模块，为Hadoop各个子项目提供各种工具，如：配置文件和日志操作等。</p><h4 id="三、运行模式"><a href="#三、运行模式" class="headerlink" title="三、运行模式"></a>三、运行模式</h4></li><li>本地模式（默认模式）：不需要启用单独进程，直接可以在运行、测试和开发时使用。</li><li>伪分布式模式：等同于完全分布式，只有一个节点。</li><li>完全分布式模式：多个节点一起运行。</li></ul><h4 id="四、伪分布式"><a href="#四、伪分布式" class="headerlink" title="四、伪分布式"></a>四、伪分布式</h4><h6 id="1-配置环境变量"><a href="#1-配置环境变量" class="headerlink" title="1. 配置环境变量"></a>1. 配置环境变量</h6><ul><li>安装JDK，配置环境变量</li><li>安装HADOOP，配置环境变量</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vi /etc/profile</span><br><span class="line"></span><br><span class="line">export JAVA_HOME=JDK路径</span><br><span class="line">export HADOOP_HOME=hadoop路径</span><br><span class="line">PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line">PATH=$PATH:$HADOOP_HOME/bin</span><br><span class="line">PATH=$PATH:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;保存后刷新</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><h6 id="2-修改配置文件"><a href="#2-修改配置文件" class="headerlink" title="2. 修改配置文件"></a>2. 修改配置文件</h6><p>&emsp;&emsp;（1）hadoop-env.sh<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=JDK路路径</span><br></pre></td></tr></table></figure></p><p>  &emsp;&emsp;（2）core-site.xml<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS中的NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">&lt;!-- 使用主机名或ip --&gt;</span><br><span class="line">&lt;value&gt;hdfs://主机名:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 指定hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;!-- 默认路径/tmp/hadoop-$&#123;user.name&#125; --&gt;</span><br><span class="line">&lt;value&gt;/hadoop安装目录/data/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>  &emsp;&emsp;（3）hdfs-site.xml<br>   <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定HDFS副本的数量 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;!-- 默认为3，伪分布式为单机模式，设置成1 --&gt;</span><br><span class="line">&lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><h6 id="3-启动集群"><a href="#3-启动集群" class="headerlink" title="3. 启动集群"></a>3. 启动集群</h6><p> &emsp;&emsp;（1）格式化namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenade -format</span><br></pre></td></tr></table></figure><p> &emsp;&emsp;只需要在修改配置后格式化一次，格式化后会生成data和logs文件夹。<br>  &emsp;&emsp;（2）启动namenode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure><p>  &emsp;&emsp;（3）启动datanode</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure><h6 id="5-查看集群"><a href="#5-查看集群" class="headerlink" title="5. 查看集群"></a>5. 查看集群</h6><p>   &emsp;&emsp;（1）jps（类似ps命令，只列出java相关程序进程）<br>   &emsp;&emsp;（2）查看日志，hadoop安装目录下的logs文件夹<br>   &emsp;&emsp;（3）使用hadoop系统自带的web程序<br>   &emsp;&emsp;&emsp;  http://主机名或ip:50070 访问HDFS系统</p><h6 id="6-操作集群"><a href="#6-操作集群" class="headerlink" title="6. 操作集群"></a>6. 操作集群</h6><blockquote><p>hadoop提供三套操作集群的命令，命令格式相同，①hdfs dfs，②hadoop dfs，③hadoop fs，使用hadoop fs，可操作任何类型的文件系统，其他两种只能操作HDFS.</p></blockquote><p>  &emsp;&emsp;（1）HDFS上创建文件夹<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir -p /hdfs上文件夹路径</span><br></pre></td></tr></table></figure></p><p>  &emsp;&emsp;（2）从linux上传文件到HDFS<br> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -put linux上文件路径 /hdfs上文件夹路径</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;（3）查看HDFS目录结构和文件内容<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -ls /hdfs上文件夹路径</span><br><span class="line">hadoop fs -cat /hdfs上文件路径</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;（4）在HDFS上运行官方示例<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop安装目录/share/hadoop/mapreduce/hadoop-mapreduce-examples-版本号.jar 示例程序名称（wordcount） /HDFS输入文件夹 /HDFS输出文件夹</span><br><span class="line"></span><br><span class="line">#输出文件夹不可事先拥有。</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;（5）从HDFS上下载文件到linux<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -get /hdfs上文件路径 /linux文件夹</span><br></pre></td></tr></table></figure></p><p>  &emsp;&emsp;（6）HDFS删除<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -rmr /hdfs上文件或文件夹路径</span><br></pre></td></tr></table></figure></p><h6 id="7-配置YARN"><a href="#7-配置YARN" class="headerlink" title="7. 配置YARN"></a>7. 配置YARN</h6><p>&emsp;&emsp;（1）在yarn-env.sh和mapred-env.sh中配置JAVA_HOME<br>&emsp;&emsp;（2）yarn-site.sml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- NodeManager上运行的附属服务，许配置mapreduce_shuffle，才可运行MapReduce --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;主机名&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><p>&emsp;&emsp;（3）mapred-site.sml<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 指定MapReduce运行在Yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>在yarn集群上提交任务，等任务执行完成后，就不能查看log文件了，为了解决这个问题，可以开启historyserver，实现yarn集群上历史任务的保存，yarn的web程序中每一个job都对应一个history的链接。</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- 历史服务器地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;主机名:10020&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;!-- 历史服务器的web程序地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">&lt;value&gt;主机名:19888&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure><h6 id="8-启动集群"><a href="#8-启动集群" class="headerlink" title="8. 启动集群"></a>8. 启动集群</h6><p>  <strong><em>必须先启动HDFS，再启动YARN。停止时先停止YARN，再停止HDFS</em></strong></p><p>  &emsp;&emsp;（1）格式化namenode(需先删除data和logs文件夹)<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs namenode -format</span><br></pre></td></tr></table></figure></p><p>  &emsp;&emsp;（2）启动NameNode和DataNode<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line">hadoop-daemon.sh start datanode</span><br></pre></td></tr></table></figure></p><p>  &emsp;&emsp;（3）启动ResourceManager和NodeManager<br>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yarn-daemon.sh start resourcemanager</span><br><span class="line">yarn-daemon.sh start nodemanager</span><br></pre></td></tr></table></figure></p><h6 id="8-集群测试"><a href="#8-集群测试" class="headerlink" title="8. 集群测试"></a>8. 集群测试</h6><p>&emsp;&emsp;（1）查看yarn的web程序：http://主机名:8088<br>&emsp;&emsp;（2）命令行操作HDFS：hadoop fis -xxx<br>&emsp;&emsp;（3）查看HDFS的web程序：http://主机名:50070<br>&emsp;&emsp;（4）执行官方测试程序dataword<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop jar hadoop安装目录/share/hadoop/mapreduce/hadoop-mapreduce-examples-版本号.jar wordcount /HDFS输入文件夹 /HDFS输出文件夹</span><br></pre></td></tr></table></figure></p><blockquote><p>输出文件夹不可事先拥有。输入文件为统计每个单词个数，实现常见一个文本，编写若干个单词，空格或换行分割。然后上传到HDFS上，事先创建输入文件夹，将该文档上传于输入文件夹，最后运行上面命令。执行完成可查看输出文件夹内文件内容，便为“单词 个数”数行形式展现。</p></blockquote>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;概念&quot;&gt;&lt;a href=&quot;#概念&quot; class=&quot;headerlink&quot; title=&quot;==概念==&quot;&gt;&lt;/a&gt;==概念==&lt;/h3&gt;&lt;blockquote&gt;
&lt;p&gt;海量、高增长、多样化的信息数据&lt;br&gt;有三大发行版本&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Apache、CDH、HDP&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
    
    </summary>
    
      <category term="hadoop" scheme="http://yoursite.com/categories/hadoop/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
      <category term="hadoop" scheme="http://yoursite.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>linux下配置ftp（centos7）</title>
    <link href="http://yoursite.com/2019/03/25/linux-ftp-conf/"/>
    <id>http://yoursite.com/2019/03/25/linux-ftp-conf/</id>
    <published>2019-03-25T06:49:51.000Z</published>
    <updated>2019-03-28T10:56:23.528Z</updated>
    
    <content type="html"><![CDATA[<h4 id="1-安装"><a href="#1-安装" class="headerlink" title="1.安装"></a>1.安装</h4><h5 id="emsp-1-1-准备工作"><a href="#emsp-1-1-准备工作" class="headerlink" title="&emsp;1.1 准备工作"></a>&emsp;1.1 准备工作</h5><p>&emsp;&emsp;关闭防火墙</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">#在centos6中使用命令 service iptables stop</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;拥有固定ip</p><h5 id="emsp-1-2-yum安装"><a href="#emsp-1-2-yum安装" class="headerlink" title="&emsp;1.2 yum安装"></a>&emsp;1.2 yum安装</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install vsftpd lftp ftp</span><br></pre></td></tr></table></figure><h5 id="emsp-1-3-关闭开机启动"><a href="#emsp-1-3-关闭开机启动" class="headerlink" title="&emsp;1.3 关闭开机启动"></a>&emsp;1.3 关闭开机启动</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld</span><br><span class="line">#在centos6中使用命令 chkconfig vsftpd off</span><br></pre></td></tr></table></figure><h4 id="2-简介"><a href="#2-简介" class="headerlink" title="2.简介"></a>2.简介</h4><blockquote><p>ftp：文件传输协议<br>协议名：ftp<br>软件包：vsftpd<br>ftp端口：控制端口 21/tcp   数据端口 20/tcp<br>配置文件：/etc/vsftpd/vsftpd.conf</p></blockquote><p>&emsp;&emsp;(1)控制端口是用来建立连接的，不能传输数据。<br>&emsp;&emsp;(2)主动模式是服务器主动送达，客户端需提供地址，不安全。<br>&emsp;&emsp;(3)被动模式是客户端去服务器获取。<br>&emsp;&emsp;(4)主动和被动是由客户端决定。<br>&emsp;&emsp;<code>vi /etc/lftp.conf</code><br>&emsp;&emsp;主动模式<br>&emsp;&emsp;<code>set ftp:passive-mode off</code><br>&emsp;&emsp;被动模式<br>&emsp;&emsp;<code>set ftp:passive-mode on</code><br>&emsp;&emsp;服务器关闭被动模式<br>&emsp;&emsp;<code>vi /etc/vsftpd/vsftpd.conf</code><br>&emsp;&emsp;<code>pasv_enable=no</code></p><h4 id="3-配置文件"><a href="#3-配置文件" class="headerlink" title="3.配置文件"></a>3.配置文件</h4><p>&emsp;&emsp;==vsftpd.conf==</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">#是否允许用户匿名登录</span><br><span class="line">anonymous_enable=YES</span><br><span class="line">#是否允许本地用户登录</span><br><span class="line">local_enable=YES</span><br><span class="line">#是否允许写</span><br><span class="line">write_enable=YES</span><br><span class="line">#控制本地用户上传文件的默认权限</span><br><span class="line">local_umask=022</span><br><span class="line">#控制匿名用户上传文件的默认权限</span><br><span class="line">anon_umask=022</span><br><span class="line">#匿名用户限速</span><br><span class="line">anon_max_rate=500000</span><br><span class="line">#本地用户限速</span><br><span class="line">local_max_rate=80000</span><br><span class="line">#ftp用户最大连接数（匿名用户不受限制）</span><br><span class="line">max_clients=500</span><br><span class="line">#单个ip最大连接数、线程数</span><br><span class="line">max_per_ip=2</span><br><span class="line">#指定本地用户访问root的目录</span><br><span class="line">local_root=/ftproot</span><br><span class="line">#指定匿名用户访问root的目录</span><br><span class="line">anon_root=/anonroot</span><br><span class="line">#处于安全考虑，应把所有用户锁定在自己的家目录</span><br><span class="line">chroot_local_user=YES</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">#限制用户登录ftp</span><br><span class="line">#黑名单</span><br><span class="line">#开启黑名单功能</span><br><span class="line">userlist_enable=YES</span><br><span class="line">#确定黑名单（默认）</span><br><span class="line">userlist_deny=YES</span><br><span class="line">#名单文件 默认存在</span><br><span class="line">userlist_file=/etc/vsftpd/user_list</span><br><span class="line">#白名单</span><br><span class="line">#确认白名单</span><br><span class="line">userlist_deny=NO</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h4 id=&quot;1-安装&quot;&gt;&lt;a href=&quot;#1-安装&quot; class=&quot;headerlink&quot; title=&quot;1.安装&quot;&gt;&lt;/a&gt;1.安装&lt;/h4&gt;&lt;h5 id=&quot;emsp-1-1-准备工作&quot;&gt;&lt;a href=&quot;#emsp-1-1-准备工作&quot; class=&quot;headerlink
      
    
    </summary>
    
      <category term="配置" scheme="http://yoursite.com/categories/%E9%85%8D%E7%BD%AE/"/>
    
    
      <category term="linux" scheme="http://yoursite.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>总结一些linux的基本命令</title>
    <link href="http://yoursite.com/2019/03/14/linuxCommand/"/>
    <id>http://yoursite.com/2019/03/14/linuxCommand/</id>
    <published>2019-03-14T02:56:32.000Z</published>
    <updated>2019-03-14T02:59:31.873Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简要"><a href="#简要" class="headerlink" title="简要"></a>简要</h2><p>一些基本的linux命令，我认为像这些命令之类的，必须要多谢多用才能熟记。</p><h4 id="基本命令与解释"><a href="#基本命令与解释" class="headerlink" title="基本命令与解释"></a>基本命令与解释</h4><p>1.<strong>mkdir</strong>        创建目录</p><pre><code>-p    创建递归目录</code></pre><p>2.<strong>touch</strong>        创建文件或修改文件时间</p><pre><code>-a    仅修改读取时间（atime）-m    仅修改修改时间（mtime）、-d    两者都修改</code></pre><p>3.<strong>cat</strong>        查看文件</p><pre><code>-n    显示行号</code></pre><p>4.<strong>less</strong></p><pre><code>more        分页查看</code></pre><p>5.<strong>head</strong>        从头查看</p><p>6.<strong>tail</strong>        从后看</p><pre><code>-f         实时查看日志文件</code></pre><p>7.<strong>grep</strong>        筛选，常配合管道使用</p><pre><code>-n显示收集到信息的行号-v用于反选信息</code></pre><p>8.<strong>wc</strong>        -l  统计行数、-w   字节数、-c  单词数</p><p>9.<strong>du</strong>        查看大小</p><p>10.<strong>cp  (旧)  (新) </strong>         复制</p><p>11.<strong>mv  (旧)  (新)</strong>         剪切或重命名</p><p>12.<strong>useradd</strong>        添加用户（只删除用户，目录保留，添加-r参数，用户目录都删除）</p><pre><code>userdel 删除用户whoami 查询当前用户名称</code></pre><p>13.<strong>groupadd</strong>        添加用户组</p><p>14.<strong>chmod [ugoa]+[rwx] 文件</strong></p><pre><code>chmod ___ 文件        4r    2w    1x</code></pre><p>15.<strong>echo</strong>        输出</p><p>16.<strong>date</strong>        用于显示及设置系统的时间或日期</p><pre><code>-s “”设置时间</code></pre><p>17.<strong>reboot</strong>        重启系统</p><p>18.<strong>poweroff</strong>        关闭系统</p><p>19.<strong>wegt</strong>        下周网络文件</p><pre><code>-p        下载到指定目录-r        递归下载</code></pre><p>20.<strong>ps</strong>        查看系统中进程状态</p><pre><code>-aux显示：R（运行）S（终端）D（不可中断）Z（僵死）T（停止）</code></pre><p>21.<strong>top</strong>        动态监视进程活动和系统负载信息</p><pre><code>第一行：系统时间    运行时间    显示终端数    系统负载第二行：进程总数    运行中的进程数    睡眠中的进程数    停止的进程数    僵死的进程数第三行：（百分比）用户占用    系统内核占用    改变过优先级的进程    空闲的资源第四行：物理内存总量比    内存使用量    内存空闲量    作为内存缓存的内存量第五行：虚拟内存总量    虚拟内存使用量    虚拟内存空闲量    已被提前加载的内存量</code></pre><p>22.<strong>pidof</strong>        查询某个服务的pid值</p><p>23.<strong>kill</strong>        用于终止某个指定pid的服务进程</p><p>24.<strong>killall</strong>        终止某个指定名称的服务所对应的全部进程</p><p>25.<strong>ifconfig</strong>        获取网咖配置与网络状态信息</p><p>26.<strong>uanme</strong>        -a    查看系统内核与系统版本等信息</p><p>27.<strong>uptime</strong>        查看系统的负载信息</p><p>28.<strong>free</strong>        -h    显示当前系统中内存使用量情况</p><p>29.<strong>who</strong>        查看登入主机的用户终端信息</p><p>30.<strong>last</strong>        查看所有系统的登录记录</p><p>31.<strong>history</strong>        显示历史执行过的命令    通过“!命令符号”执行某条命令</p><pre><code>-c    清空</code></pre><p>32.<strong>sosreport</strong>        收集系统配置及架构信息并输出诊断文档</p><p>33.<strong>pwd</strong>        显示当前目录</p><p>32.<strong>cd</strong>        切换目录</p><p>33.<strong>ls</strong>    ll        查看当前目录下的文件</p><p>34.<strong>tr  (old) (new)</strong>    替换文件中的字符</p><p>35.<strong>stat</strong>        查看文件具体存储信息和时间</p><pre><code>access    modify    change</code></pre><p>36.<strong>cut</strong>        按列提取文本字符</p><pre><code>-d    紧跟分隔符-f    紧跟列号</code></pre><p>37.<strong>diff</strong>        比较多个文件文本的差异</p><pre><code>--brief    判断文件是否相同-c       显示文件具体的不同</code></pre><p>38.<strong>rm</strong>        删除</p><pre><code>-f    无需二次确认-rf    强制删除</code></pre><p>39.<strong>file</strong>        查看文件的类型</p><p>40.<strong>tar</strong>        解压缩</p><pre><code>一般压缩-czvf    一般解压-xzvf</code></pre><p>41.<strong>find</strong>        按照指定条件查找文件</p><pre><code>-name-user-group   -mtime -n +n        -n指n天以内，+n指n天以前-atime -n +n-ctime -n +n</code></pre><p>42.<strong>fdisk</strong>    -l    查看磁盘</p><p>43.<strong>vim编辑器</strong></p><pre><code>dd删除yy复制v撤销上一步操作p粘贴:w    q     wq     q!    wq!:set nu         显示行号:set nonu        不显示行号:命令            执行该命令:整数        跳转到该行</code></pre><p>44.<strong>crontab</strong>        定时任务</p><pre><code>-e编辑    -l查询    -r删除当前用户的所有任务编辑格式        *    *    *    *    *    第一个：一小时内的第几分钟执行0-59    第二个：一天中的第几个小时执行0-23    第三个：一个月中第几天执行1-31    第四个：一年中当中的第几个月执行1-12    第五个：一周当中星期几执行0-7（0和7都是周日）特殊符号    * 任何时间    ，多个时间分割       - 连续时间    */n每个n执行一次无效服务时重启定时服务service crond restart</code></pre><p>45.<strong>sync</strong>     将内存数据同步到磁盘，关机重启都应该执行</p><hr>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简要&quot;&gt;&lt;a href=&quot;#简要&quot; class=&quot;headerlink&quot; title=&quot;简要&quot;&gt;&lt;/a&gt;简要&lt;/h2&gt;&lt;p&gt;一些基本的linux命令，我认为像这些命令之类的，必须要多谢多用才能熟记。&lt;/p&gt;
&lt;h4 id=&quot;基本命令与解释&quot;&gt;&lt;a href=&quot;#基
      
    
    </summary>
    
      <category term="linux" scheme="http://yoursite.com/categories/linux/"/>
    
    
      <category term="linux命令" scheme="http://yoursite.com/tags/linux%E5%91%BD%E4%BB%A4/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2019/03/11/hello-world/"/>
    <id>http://yoursite.com/2019/03/11/hello-world/</id>
    <published>2019-03-11T13:03:36.838Z</published>
    <updated>2019-03-11T13:03:36.838Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>B/S基于springMVC的网上选课系统</title>
    <link href="http://yoursite.com/2018/12/08/onlineSC-springmvc/"/>
    <id>http://yoursite.com/2018/12/08/onlineSC-springmvc/</id>
    <published>2018-12-07T17:07:22.000Z</published>
    <updated>2019-03-25T06:07:10.846Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简要"><a href="#简要" class="headerlink" title="简要:"></a>简要:</h2><p>去年花了一周时间自己在课设上写的，基于springMVC的网上选课系统。</p><hr><h4 id="使用说明"><a href="#使用说明" class="headerlink" title="使用说明"></a>使用说明</h4><ol><li>windows系统</li><li>java8环境</li><li>tomcat9环境</li><li>mysql5.5数据库， 用户名root，密码root</li><li>eclipse需配置jre和tomcat。可由eclipse直接导入工程使用</li></ol><h4 id="1-设计选题"><a href="#1-设计选题" class="headerlink" title="1.设计选题"></a>1.设计选题</h4><h5 id="emsp-1-1-设计选题"><a href="#emsp-1-1-设计选题" class="headerlink" title="&emsp;1.1 设计选题"></a>&emsp;1.1 设计选题</h5><p>&emsp;&emsp;《网上选课系统》</p><h5 id="emsp-1-2-设计背景"><a href="#emsp-1-2-设计背景" class="headerlink" title="&emsp;1.2 设计背景"></a>&emsp;1.2 设计背景</h5><p>&emsp;&emsp;随着在校人数的增加，选课是重点问题，拥有一个好的网上选课系统可以简便快速的对选课各种信息进行管理，节省了人力和时间，提高了对课程管理的效率。</p><h4 id="2-需求分析"><a href="#2-需求分析" class="headerlink" title="2.需求分析"></a>2.需求分析</h4><p>&emsp;分为三种用户：管理员、学生、教师。<br><strong>&emsp;管理员：</strong></p><p> &emsp; 1.登录功能</p><blockquote><p>需求描述：通过已知的管理员账号登录，登录成功进入管理员界面，方可执行相应功能。</p></blockquote><p>   &emsp;2.添加教师信息</p><blockquote><p>需求描述：添加一个新的教师信息，教师工号作为教师身份唯一标识，添加时会对输入框中教师工号是否存在进行判断并提示。</p></blockquote><p>&emsp;3.修改教师信息</p><blockquote><p>需求描述：可以选择教师并修改其信息，教师编号不可修改。</p></blockquote><p>&emsp;4.删除教师信息</p><blockquote><p>需求描述：删除某一条选中教师的所有信息。</p></blockquote><p>&emsp;5.查询教师信息</p><blockquote><p>需求描述：选择查询条件，可查询所有教师、通过教师编号查询教师信息，并以表格的形式显示出来。</p></blockquote><p>&emsp;6.添加课程信息</p><blockquote><p>需求描述：添加一个新的课程信息，课程编号作为该课程身份唯一标识，添加时会对输入框中课程编号是否存在进行判断并提示。其中一些属性通过下拉框方便选择。</p></blockquote><p>&emsp;7.修改课程信息</p><blockquote><p>需求描述：可对选中的课程进行修改，其中课程编号不可修改</p></blockquote><p>&emsp;8.删除课程信息</p><blockquote><p>需求描述：删除选定课程的所有信息。</p></blockquote><p>&emsp;9.查询课程信息</p><blockquote><p>需求描述：根据相应条件查询课程，所有课程、根据编号、课程类型、所属学院等进行查询。</p></blockquote><p>&emsp;10.添加学生信息</p><blockquote><p>需求描述：添加一个新的学生信息，学号作为学生身份唯一标识，添加时会对输入框中学号是否存在进行判断并提示。其中学院、专业等信息通过下拉框方便选择。</p></blockquote><p>&emsp;11.修改学生信息</p><blockquote><p>需求描述：修改选中学生的信息，其中学号不可修改。</p></blockquote><p>&emsp;12.删除学生信息</p><blockquote><p>需求描述：删除选中学生的所有信息。</p></blockquote><p>&emsp;13.查询学生信息</p><blockquote><p>需求描述：通过相应条件查询学生，例如查询所有信息，通过学号、学院、专业、班级等条件查询学生信息。</p></blockquote><p><strong>&emsp;教师：</strong></p><p>&emsp;1.查询个人信息</p><blockquote><p>需求描述：可以查询自己的所有信息</p></blockquote><p>&emsp;2.修改个人信息</p><blockquote><p>需求描述：只能修改自己密码，其他信息都不可修改</p></blockquote><p>&emsp;3.选择课程</p><blockquote><p>需求描述：通过查询课程表，查看已有课程，并选择自己需要教学的课程。</p></blockquote><p>&emsp;4.添加课程安排</p><blockquote><p>需求描述：通过选择一门已有课程，对该课程进行安排包括上课班级名、上课时间、所在教师、学分学时、总人数等。</p></blockquote><p>&emsp;5.修改课程安排</p><blockquote><p>需求描述：修改自己已经安排的课程的信息。</p></blockquote><p>&emsp;6.删除课程安排</p><blockquote><p>需求描述：删除自己已经安排的课程的信息。</p></blockquote><p>&emsp;7.查询课程安排</p><blockquote><p>需求描述：查询自己的已选教学课程的各种信息</p></blockquote><p>&emsp;8.查询选课信息</p><blockquote><p>需求描述：选定自己教学课程，查看该课程的学生学科情况，包括一些学生信息。</p></blockquote><p>&emsp;9.打印选课信息</p><blockquote><p>需求描述：选择自己教学的一门课程，并打印出该课程的学生信息。</p></blockquote><p><strong>&emsp;学生：</strong></p><p>&emsp;1.修改个人信息</p><blockquote><p>需求描述：只能修改自己的密码，其他信息需联系管理员修改。</p></blockquote><p>&emsp;2.选课</p><blockquote><p>需求描述：选择一门已有课程，并进入确认，提示学习该课程是否已有教师安排。</p></blockquote><p>&emsp;3.查询课程安排</p><blockquote><p>需求描述：查询自己所选课程的信息。</p></blockquote><p>&emsp;4.查询选课人数</p><blockquote><p>需求描述：查询课程已选人数。</p></blockquote><p>&emsp;5.退选。</p><blockquote><p>需求描述：退选自己已选课程。</p></blockquote><h4 id="3-系统的开发运行环境"><a href="#3-系统的开发运行环境" class="headerlink" title="3.系统的开发运行环境"></a>3.系统的开发运行环境</h4><ul><li>本系统开发平台: JSP + MYSQL</li><li>本系统集成开发环境: Eclipse + Tomcat</li><li>本系统运行环境: Windows OS</li></ul><h4 id="4-程序功能模块图及数据流图"><a href="#4-程序功能模块图及数据流图" class="headerlink" title="4.程序功能模块图及数据流图"></a>4.程序功能模块图及数据流图</h4><h5 id="emsp-4-1-程序功能模块图"><a href="#emsp-4-1-程序功能模块图" class="headerlink" title="&emsp;4.1 程序功能模块图"></a>&emsp;4.1 程序功能模块图</h5><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20181206211141727.png" alt></p><h5 id="emsp-4-1-数据流图"><a href="#emsp-4-1-数据流图" class="headerlink" title="&emsp;4.1 数据流图"></a>&emsp;4.1 数据流图</h5><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20181206211141848.png" alt></p><h4 id="5-总体设计"><a href="#5-总体设计" class="headerlink" title="5.总体设计"></a>5.总体设计</h4><h5 id="emsp-5-1-系统体系结构设计"><a href="#emsp-5-1-系统体系结构设计" class="headerlink" title="&emsp;5.1 系统体系结构设计"></a>&emsp;5.1 系统体系结构设计</h5><blockquote><p>界面首先为选择登录身份，选择后进入相应登录界面，登陆成功后的主界面由两块组成，一个为左栏，用于显示功能以及功能操作的，可以手动隐藏和显示；还有主界面，用于操作对应功能以及查看结果等。主界面内含一个div盒子，用于美观。使用户能够在简单、易用、单一、统一的可视化界面下，轻松、方便地访问到各种类型的数据。</p></blockquote><h5 id="emsp-5-2-系统功能说明"><a href="#emsp-5-2-系统功能说明" class="headerlink" title="&emsp;5.2 系统功能说明"></a>&emsp;5.2 系统功能说明</h5><p>&emsp;1.管理员</p><p>&emsp;&emsp;①可以对学生信息通过诸多条件进行查询；</p><p>&emsp;&emsp;②可以对学生信息进行修改以及删除；</p><p>&emsp;&emsp;③添加一个新的学生信息</p><p>&emsp;&emsp;④可以对教师信息查询、修改、删除以及添加。</p><p>&emsp;&emsp;⑤可对课程进行修改、删除、查询、以及添加。</p><p>&emsp;2.教师</p><p>&emsp;&emsp;①可以查询管理员添加的课程信息，并选择自己需要教学的课程。</p><p>&emsp;&emsp;②选择自己教学课程后对该课程进行安排，包括上课时间、上课地点、学分、学时、总人数等。</p><p>&emsp;&emsp;③可以对自己已选教学课程的课程安排进行修改、删除等操作。</p><p>&emsp;&emsp;④可以查询自己教学课程的学生选课信息。</p><p>&emsp;&emsp;⑤查看自己信息，并可以修改密码。</p><p>&emsp;3.学生</p><p>&emsp;&emsp;①可以查询全部管理员已添加的课程，并可以通过课程编号、课程名、课程所属专业、课程类型等条件查询。</p><p>&emsp;&emsp;②可以选择查询出来的课程进行选课，选择后进入确认界面，显示课程名，提示是否已有教师安排此课，若有则显示教师姓名，并有确认和取消两个按钮，确认则选课成功，取消则返回上一界面。</p><p>&emsp;&emsp;③查看选课结果，用表格形式显示出课程名、上课教室、上课地点、学分、学时以及代课教师。没有教师安排的课程无法查出，只能在退选中查看单独的课程名。</p><p>&emsp;&emsp;④退选已选课程，先查询出自己已选的所有课程，通过课程名选择退选。</p><p>&emsp;&emsp;⑤查看个人所有信息，只可以修改密码。</p><h5 id="emsp-5-3-数据库设计"><a href="#emsp-5-3-数据库设计" class="headerlink" title="&emsp;5.3 数据库设计"></a>&emsp;5.3 数据库设计</h5><blockquote><p>总共六个表：学生表、教师表、管理员表、课程表、课程安排表、选课表。</p></blockquote><p>&emsp;&emsp;管理员表admin</p><table><thead><tr><th>列名</th><th>类型</th><th>约束</th><th>备注</th></tr></thead><tbody><tr><td>Aname</td><td>Varchar（12）</td><td>主键</td><td>账号</td></tr><tr><td>Apassword</td><td></td><td></td><td>密码</td></tr></tbody></table><p>&emsp;&emsp;学生表Student</p><table><thead><tr><th>列名</th><th>类型</th><th>约束</th><th>备注</th></tr></thead><tbody><tr><td>Sid</td><td>Char(12)</td><td>非空、主键</td><td>学号</td></tr><tr><td>Sname</td><td>Varchar（8）</td><td>非空</td><td>姓名</td></tr><tr><td>Sidcard</td><td>Char(18)</td><td>非空</td><td>身份证</td></tr><tr><td>Ssex</td><td>Char(2)</td><td>男女</td><td>性别</td></tr><tr><td>Spassword</td><td>Varchar(12)</td><td>非空</td><td>密码</td></tr><tr><td>Sage</td><td>Char（2）</td><td></td><td>年龄</td></tr><tr><td>Classr</td><td>Varchar（15）</td><td></td><td>班级</td></tr><tr><td>profession</td><td>Varchar（15）</td><td></td><td>专业</td></tr><tr><td>College</td><td>Varchar（15）</td><td></td><td>学院</td></tr></tbody></table><p>&emsp;&emsp;教师表Teacher</p><table><thead><tr><th>列名</th><th>类型</th><th>约束</th><th>备注</th></tr></thead><tbody><tr><td>Tid</td><td>Char（4）</td><td>主键</td><td>工号</td></tr><tr><td>Tname</td><td>Varchar(8)</td><td></td><td>姓名</td></tr><tr><td>Tpassword</td><td>Varchar(12)</td><td></td><td>密码</td></tr><tr><td>Tsex</td><td>Char(2)</td><td>男女</td><td>性别</td></tr><tr><td>Introduction</td><td>Varchar（100）</td><td></td><td>简介</td></tr></tbody></table><p>&emsp;&emsp;课程表course</p><table><thead><tr><th>列名</th><th>类型</th><th>约束</th><th>备注</th></tr></thead><tbody><tr><td>Cid</td><td>Char（4）</td><td>主键</td><td>课程号</td></tr><tr><td>Cname</td><td>varChar(15)</td><td></td><td>课程名</td></tr><tr><td>Cintroduction</td><td>Varchar（100）</td><td></td><td>简介</td></tr><tr><td>Type</td><td>Varchar（15）</td><td></td><td>类型（选修，必修）</td></tr><tr><td>Belongcoll</td><td>Varchar（15）</td><td></td><td>所属学院</td></tr><tr><td>Belongpro</td><td>Varchar（15）</td><td></td><td>所属专业</td></tr></tbody></table><p>&emsp;&emsp;课程安排</p><table><thead><tr><th>列名</th><th>类型</th><th>约束</th><th>备注</th></tr></thead><tbody><tr><td>Courseclass</td><td>Varchar（12）</td><td>主键</td><td>开课班级</td></tr><tr><td>Coursetime</td><td>Varchar（12）</td><td></td><td>上课时间</td></tr><tr><td>Courseweek</td><td>Varchar（12）</td><td></td><td>上课周</td></tr><tr><td>Cid</td><td>Char（4）</td><td>外键</td><td>课程号</td></tr><tr><td>Tid</td><td>Char（4）</td><td>外键</td><td>教师编号</td></tr><tr><td>Classroom</td><td>Varchar（6）</td><td></td><td>上课教室</td></tr><tr><td>credits</td><td>Int（11）</td><td></td><td>学分</td></tr><tr><td>period</td><td>Int（11）</td><td></td><td>学时</td></tr><tr><td>Totalnum</td><td>Int（11）</td><td></td><td>总人数</td></tr></tbody></table><p>&emsp;&emsp;选课表sc</p><table><thead><tr><th>列名</th><th>类型</th><th>约束</th><th>备注</th></tr></thead><tbody><tr><td>Id</td><td>varChar（4）</td><td>自动增长、主键</td><td>用于传值</td></tr><tr><td>Sid</td><td>Char(12)</td><td>外键</td><td>学生学号</td></tr><tr><td>Cid</td><td>Char（4）</td><td>外键</td><td>课程编号</td></tr></tbody></table><h5 id="emsp-5-4-界面设计"><a href="#emsp-5-4-界面设计" class="headerlink" title="&emsp;5.4 界面设计"></a>&emsp;5.4 界面设计</h5><p><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20181206211141919.png" alt><br>&emsp;登录（以管理员为例）<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20181206211141945.png" alt><br>&emsp;管理员登录界面，左侧栏可收缩<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20181206211145307.png" alt></p><h4 id="6-实现"><a href="#6-实现" class="headerlink" title="6.实现"></a>6.实现</h4><h5 id="emsp-6-1-程序结构"><a href="#emsp-6-1-程序结构" class="headerlink" title="&emsp;6.1 程序结构"></a>&emsp;6.1 程序结构</h5><blockquote><p>网上选课系统利用MVC设计模式，利用spring mvc框架，将其分为视图层、控制器层、模型层。视图层为jsp文件，分别存放在admin、teacher、student三个文件夹中，分别是管理员界面、教师界面、学生界面，而index和登录界面以及操作成功失败界面直接放在主目录；控制器层为servlet类，用来处理视图层发送的每个请求，存放在以域名翻转命名的包内：net.fuzui.servlet；模型层用来存放javabean类，分为实体bean和业务bean中，分别放在以域名翻转命名包net.fuzui.beans、net.fuzui.dao中，实体bean存放实体类，业务bean中存放数据库连接以及对数据库的操作，由servlet调用。</p></blockquote><h5 id="emsp-6-2-应用技术及实现"><a href="#emsp-6-2-应用技术及实现" class="headerlink" title="&emsp;6.2 应用技术及实现"></a>&emsp;6.2 应用技术及实现</h5><blockquote><p>&emsp;&emsp;在网上选课系统中，用到基于注解的spring mvc框架，在视图层中的每一次请求都会发送到控制器层，由servlet类通过注解识别请求，处理请求，需要用到数据库时则调用DAO。先通过配置web.xml以及springmvc.xml来应用框架，由@RequestMapping 来处理请求映射，在处理url和表单提交时，会自动根据url或者表单中参数的名字和方法中同名形参进行匹配并赋值。<br>&emsp;&emsp;在添加学生、教师、课程信息时，通过jQuery运用ajax技术，如果添加的学号已存在，在输入框右侧会红字提示该学号已存在，不存在也会有提醒该学号可添加，教师工号、课程编号也如此。<br>&emsp;&emsp;在学生界面查询选课结果时，利用了数据库表与表之间级联，通过选课表、课程表、课程安排表、教师表四表级联的sql语句，查询出课程名、班级名称、上课时间、教室、学分学时以及代课老师信息，并将此信息存放在一个实体类中，方便调用。<br>&emsp;&emsp;在视图层的样式设计中，通过css设置背景色透明度渐变和背景图片透明度来实现整体视觉效果，在该系统中，表比较多，所以将表的样式也焕然一新。总界面分为左侧栏和显示栏，运用js，左侧栏通过点击相应图标可收缩隐藏。运用了el表达式和jstl标记，是界面更加简约。</p></blockquote><h4 id="6-展示和下载"><a href="#6-展示和下载" class="headerlink" title="6.展示和下载"></a>6.展示和下载</h4><p>&emsp;项目展示：<a href="onlineSC.fuzui.net">onlineSC.fuzui.net</a></p><blockquote><p>管理员用户名admin，密码admin，以供测试，学生和教师账号密码可通过管理员登录查看。<br>这个小项目里还是有不少bug的，不够完善。</p></blockquote><p>&emsp;github源码：<a href="https://github.com/fuzui/onlineSC" target="_blank" rel="noopener">https://github.com/fuzui/onlineSC</a></p><p>最后附上项目目录：<br><img src="https://fuzui.oss-cn-shenzhen.aliyuncs.com/img/20181208003711276.png" alt></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;简要&quot;&gt;&lt;a href=&quot;#简要&quot; class=&quot;headerlink&quot; title=&quot;简要:&quot;&gt;&lt;/a&gt;简要:&lt;/h2&gt;&lt;p&gt;去年花了一周时间自己在课设上写的，基于springMVC的网上选课系统。&lt;/p&gt;
&lt;hr&gt;
&lt;h4 id=&quot;使用说明&quot;&gt;&lt;a href=
      
    
    </summary>
    
      <category term="java-springMVC" scheme="http://yoursite.com/categories/java-springMVC/"/>
    
    
      <category term="项目" scheme="http://yoursite.com/tags/%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="springMVC" scheme="http://yoursite.com/tags/springMVC/"/>
    
  </entry>
  
</feed>
